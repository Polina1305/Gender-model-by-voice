# Распознавание пола по голосу с помощью нейросети
Привет! В рамках проекта я решила изучить, как можно распознавать пол человека по его голосу, используя методы глубокого обучения. Мне стало интересно, насколько точно можно научить нейросеть отличать мужские и женские голоса — и вот, что из этого получилось!

В этом репозитории представлена полная реализация модели, она собрана, обучена и протестирована. Основой послужили спектрограммы мел-шкалы (`Mel-spectrogram`), а модель построена с использованием `TensorFlow 2`.

https://github.com/user-attachments/assets/66887bc9-cddf-4601-8fd9-a9525c612a9e

## Используемые библиотеки
- TensorFlow 2.x
- Librosa
- Scikit-learn
- NumPy
- Pandas
- PyAudio
- tqdm

Установить зависимости можно командой:
```
pip install -r requirements.txt
```

### Датасет
Я использовала `Common Voice` от `Mozilla` — это большой открытый набор голосовых данных.

Предобработка данных включала:

- удаление примеров с отсутствующим или неизвестным полом;
- сохранение только мужских и женских голосов;
- сохранение признаков в .npy-файлах с помощью скрипта preparation.py.

Файлы аудио не включены (они весят более `13 ГБ`), но ты можешь загрузить их самостоятельно с `Kaggle`.


### Обучение модели
Ты можешь изменить архитектуру нейросети в utils.py, в функции create_model(), а затем запустить обучение:

```
python train.py
```

Модель будет обучаться и автоматически сохраняться в файл `results/model.h5`


### Тестирование
Модель можно протестировать либо на своём голосе, либо на WAV-файле:

```
python test.py --file "test-samples/sample.wav"
```
Или, если хочешь протестировать модель вживую, просто запусти:

```
python test.py
```
Жди приглашения: Please speak, и начни говорить в микрофон. После паузы запись автоматически завершится, и ты увидишь результат:

```makefile
Определён пол: female  
Вероятность:    Мужской: 12.75%    Женский: 87.25%
```
### Примеры
Некоторые WAV-примеры можно найти в папке test-samples, они взяты из LibriSpeech.


### Кривая обучения (оранжевая-train, синяя-test)

<img width="747" height="247" alt="image" src="https://github.com/user-attachments/assets/a7941167-e2b9-43d4-9651-253ebd82ce03" />

### Заключение
Проект стал отличной возможностью для меня не просто применить на практике нейронные сети, но и глубже понять обработку аудиосигналов. Весь pipeline — от загрузки данных до вывода результата — был мной реализован, протестирован и задокументирован.



Если ты тоже хочешь поэкспериментировать с речью, обязательно попробуй этот проект — он отлично подойдёт как база для расширений: эмоции, акценты, возраст и многое другое!

Автор проекта: [Smolyak Polina]
[Написать мне в Telegram](https://t.me/Smolyak_DS)
